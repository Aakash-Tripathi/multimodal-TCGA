{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 585/585 [00:44<00:00, 13.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " project id: TCGA-LUAD; case submitter id: TCGA-55-6971; source center: 22; state: released; normal tumor genotype snp match: Yes; age at index: 59.0; days to birth: -21734.0; ethnicity: not reported; gender: female; race: white; vital status: Alive; year of birth: 1951.0; age at diagnosis: 21734.0; ajcc pathologic m: MX; ajcc pathologic n: N0; ajcc pathologic stage: Stage IB; ajcc pathologic t: T2; ajcc staging system edition: 7th; classification of tumor: not reported; days to diagnosis: 0.0; days to last follow up: 1400.0; icd 10 code: C34.3; last known disease status: not reported; morphology: 8140/3; primary diagnosis: Adenocarcinoma, NOS; prior malignancy: no; prior treatment: No; progression or recurrence: not reported; site of resection or biopsy: Lower lobe, lung; synchronous malignancy: No; tissue or organ of origin: Lower lobe, lung; tumor grade: not reported; year of diagnosis: 2010.0; treatment or therapy: no; alcohol history: Not Reported; cigarettes per day: 3.287671232876712; pack years smoked: 60.0; years smoked: 40.0; is ffpe: 0.0; composition: Not Reported; days to sample procurement: 0.0; intermediate dimension: 0.5; oct embedded: No; preservation method: FFPE; tissue type: Not Reported; tumor descriptor: Not Reported; percent lymphocyte infiltration: 20.0; percent monocyte infiltration: 1.0; percent neutrophil infiltration: 2.0; percent tumor nuclei: 70.0; \n",
      "\n",
      "\n",
      " (524288,) -> (512, 1024)\n"
     ]
    }
   ],
   "source": [
    "from lib.MINDS import MINDS\n",
    "import pandas as pd\n",
    "import json\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from transformers import AutoModel, AutoTokenizer, AutoConfig\n",
    "import torch\n",
    "import redis\n",
    "from redis.commands.search.field import TagField, VectorField\n",
    "from redis.commands.search.indexDefinition import IndexDefinition, IndexType\n",
    "from redis.commands.search.query import Query\n",
    "\n",
    "# Check if a GPU is available and if not, use a CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "def generate_summary(patient_data):\n",
    "    # Extracting basic patient information\n",
    "    patient_id = patient_data.get(\"case_submitter_id\", \"N/A\")\n",
    "    age = patient_data.get(\"age_at_index\", \"N/A\")\n",
    "    gender = patient_data.get(\"gender\", \"N/A\")\n",
    "    ethnicity = patient_data.get(\"ethnicity\", \"N/A\")\n",
    "    diagnosis = patient_data.get(\"primary_diagnosis\", \"N/A\")\n",
    "    tumor_stage = patient_data.get(\"ajcc_pathologic_stage\", \"N/A\")\n",
    "\n",
    "    # Extracting treatment information\n",
    "    treatments = patient_data.get(\"clinical\", [])\n",
    "    treatment_types = \", \".join(t.get(\"treatment_type\", \"N/A\") for t in treatments)\n",
    "\n",
    "    # Sample and slide information\n",
    "    sample_details = patient_data.get(\"sample\", [])\n",
    "    sample_info = \"Sample details: \" + \"; \".join(\n",
    "        f\"ID: {s.get('sample_id', 'N/A')}, Type: {s.get('sample_type', 'N/A')}, FFPE: {s.get('is_ffpe', 'N/A')}\"\n",
    "        for s in sample_details\n",
    "    )\n",
    "\n",
    "    # Smoking and alcohol history\n",
    "    cigarettes_per_day = patient_data.get(\"cigarettes_per_day\", \"N/A\")\n",
    "    pack_years = patient_data.get(\"pack_years_smoked\", \"N/A\")\n",
    "    alcohol_history = patient_data.get(\"alcohol_history\", \"N/A\")\n",
    "\n",
    "    # Creating the summary\n",
    "    summary = (\n",
    "        f\"Patient ID: {patient_id}, a {age}-year-old {gender} of {ethnicity} ethnicity, \"\n",
    "        f\"was diagnosed with {diagnosis}, staged as {tumor_stage}. \"\n",
    "        f\"Treatment administered includes: {treatment_types}. \"\n",
    "        f\"{sample_info} \"\n",
    "        f\"The patient has a smoking history of {cigarettes_per_day} cigarettes per day over {pack_years} pack-years. \"\n",
    "        f\"Alcohol history: {alcohol_history}.\"\n",
    "    )\n",
    "    return summary\n",
    "\n",
    "\n",
    "def generate_summary_from_json(patient_data):\n",
    "    # Initialize an empty list to store sentences\n",
    "    summary_sentences = []\n",
    "\n",
    "    # Iterate through each key-value pair in the JSON object\n",
    "    for key, value in patient_data.items():\n",
    "        # if the key is \"case_id\" then skip it\n",
    "        if key == \"case_id\" or key == \"pathology_report_uuid\":\n",
    "            continue\n",
    "\n",
    "        # remove all _ from the key\n",
    "        key = key.replace(\"_\", \" \")\n",
    "        sentence = f\"{key}: {value};\"\n",
    "\n",
    "        # if the value is a list, then skip it\n",
    "        if isinstance(value, list):\n",
    "            continue\n",
    "\n",
    "        summary_sentences.append(sentence)\n",
    "\n",
    "    # Compile all sentences into a single summary string\n",
    "    summary = \" \".join(summary_sentences)\n",
    "\n",
    "    return summary\n",
    "\n",
    "\n",
    "def process_group(group):\n",
    "    common_fields = {}\n",
    "    nested_objects = []\n",
    "    for col in group.columns:\n",
    "        unique_values = group[col].dropna().unique()\n",
    "        if len(unique_values) == 1:\n",
    "            # If only one unique value exists, it's a common field\n",
    "            common_fields[col] = unique_values[0]\n",
    "\n",
    "    # Create nested objects for fields that are not common\n",
    "    for idx, row in group.iterrows():\n",
    "        nested_object = {\n",
    "            col: row[col]\n",
    "            for col in group.columns\n",
    "            if col not in common_fields and pd.notna(row[col])\n",
    "        }\n",
    "        if nested_object:  # Only add if the nested object is not empty\n",
    "            nested_objects.append(nested_object)\n",
    "\n",
    "    return common_fields, nested_objects\n",
    "\n",
    "\n",
    "def convert_numpy(obj):\n",
    "    if isinstance(obj, np.integer):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, np.floating):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "\n",
    "class ClinincalEmbeddings:\n",
    "    def __init__(self, model):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "        self.config = AutoConfig.from_pretrained(model)\n",
    "        self.model = AutoModel.from_pretrained(model)\n",
    "        self.model = self.model.to(device)\n",
    "\n",
    "    def generate_embeddings(self, sentences):\n",
    "        inputs = self.tokenizer(\n",
    "            str(sentences),\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "\n",
    "        embedding = outputs[\"last_hidden_state\"].cpu().numpy()\n",
    "        return embedding\n",
    "\n",
    "\n",
    "class RedisClient:\n",
    "    def __init__(self):\n",
    "        self.client = redis.Redis(host=\"10.0.1.16\", port=6379, db=0)\n",
    "        self.client.ping()\n",
    "        self.INDEX_NAME = \"clinical\"\n",
    "        self.DOC_PREFIX = \"patient:\"\n",
    "        # drop the index if it already exists\n",
    "        try:\n",
    "            self.client.execute_command(\"FT.DROPINDEX\", self.INDEX_NAME)\n",
    "            print(\"Dropped Index\")\n",
    "        except:\n",
    "            pass\n",
    "        self.create_index()\n",
    "\n",
    "    def create_index(self):\n",
    "        schema = (\n",
    "            TagField(\"case_submitter_id\"),\n",
    "            VectorField(\n",
    "                \"embedding\",\n",
    "                \"FLAT\",\n",
    "                {\n",
    "                    \"TYPE\": \"FLOAT64\",\n",
    "                    \"DIM\": 512 * 1024,\n",
    "                    \"DISTANCE_METRIC\": \"COSINE\",\n",
    "                },\n",
    "            ),\n",
    "        )\n",
    "        definition = IndexDefinition(\n",
    "            prefix=[self.DOC_PREFIX], index_type=IndexType.HASH\n",
    "        )\n",
    "        self.client.ft(self.INDEX_NAME).create_index(\n",
    "            fields=schema, definition=definition\n",
    "        )\n",
    "\n",
    "    def add_document(self, case_id, embedding):\n",
    "        embedding = embedding.astype(np.float64).tobytes()\n",
    "        pipe = self.client.pipeline()\n",
    "        pipe.hset(\n",
    "            self.DOC_PREFIX + case_id,\n",
    "            mapping={\"case_submitter_id\": case_id},\n",
    "        )\n",
    "        pipe.hset(\n",
    "            self.DOC_PREFIX + case_id,\n",
    "            mapping={\"embedding\": embedding},\n",
    "        )\n",
    "        pipe.execute()\n",
    "\n",
    "    def query(self, query):\n",
    "        result = np.frombuffer(self.client.hget(query, \"embedding\"), dtype=np.float64)\n",
    "        return result\n",
    "\n",
    "\n",
    "def main():\n",
    "    minds = MINDS()\n",
    "    clinical_model = ClinincalEmbeddings(model=\"UFNLP/gatortron-base\")\n",
    "    redis_client = RedisClient()\n",
    "\n",
    "    project_id = \"TCGA-LUAD\"\n",
    "    filename = project_id\n",
    "    tables = minds.get_tables()\n",
    "\n",
    "    if Path(f\"{filename}.json\").exists():\n",
    "        json_objects = json.load(open(f\"{filename}.json\"))\n",
    "    else:\n",
    "        json_objects = {}\n",
    "        for table in tqdm(tables[\"Tables_in_nihnci\"]):\n",
    "            query = f\"SELECT * FROM nihnci.{table} WHERE project_id='{project_id}'\"\n",
    "            df = minds.query(query)\n",
    "            for case_id, group in tqdm(df.groupby(\"case_submitter_id\"), leave=False):\n",
    "                if case_id not in json_objects:\n",
    "                    json_objects[case_id] = {}\n",
    "                common_fields, nested_objects = process_group(group)\n",
    "                json_objects[case_id].update(common_fields)\n",
    "                json_objects[case_id][table] = nested_objects\n",
    "        with open(f\"{filename}.json\", \"w\") as fp:\n",
    "            json.dump(json_objects, fp, indent=4, default=convert_numpy)\n",
    "\n",
    "    # if the redis already has the embeddings, for a given patient, then skip\n",
    "    for case_id, patient_data in tqdm(json_objects.items()):\n",
    "        if redis_client.client.exists(f\"patient:{case_id}\"):\n",
    "            continue\n",
    "        summary = generate_summary_from_json(patient_data)\n",
    "        embedding = clinical_model.generate_embeddings(summary)\n",
    "        redis_client.add_document(case_id, embedding)\n",
    "\n",
    "    random_case_id = random.choice(list(json_objects.keys()))\n",
    "    patient_data = json_objects[random_case_id]\n",
    "    summary = generate_summary_from_json(patient_data)\n",
    "    print(\"\\n\", summary, \"\\n\")\n",
    "\n",
    "    result = redis_client.query(f\"patient:{random_case_id}\")\n",
    "    print(\"\\n\", result.shape, \"->\", f\"({result.shape[0] // 1024}, 1024)\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aakas\\miniconda3\\envs\\ADA\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "c:\\Users\\aakas\\miniconda3\\envs\\ADA\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([32, 1024])) that is different to the input size (torch.Size([32, 1, 1024])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 1.3388501405715942\n",
      "Epoch 2 Loss: 1.2981369495391846\n",
      "Epoch 3 Loss: 1.2753379344940186\n",
      "Epoch 4 Loss: 1.2600343227386475\n",
      "Epoch 5 Loss: 1.2499806880950928\n",
      "Epoch 6 Loss: 1.2428406476974487\n",
      "Epoch 7 Loss: 1.2376083135604858\n",
      "Epoch 8 Loss: 1.2342753410339355\n",
      "Epoch 9 Loss: 1.2320477962493896\n",
      "Epoch 10 Loss: 1.2306965589523315\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "\n",
    "class ClinicalEmbeddings:\n",
    "    def __init__(self, model_name):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "        self.model.to(device)\n",
    "\n",
    "    def generate_embeddings(self, text):\n",
    "        inputs = self.tokenizer(\n",
    "            text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512\n",
    "        ).to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "        return outputs.last_hidden_state.mean(\n",
    "            dim=1\n",
    "        )  # Return mean pooling of the token embeddings\n",
    "\n",
    "\n",
    "class MultimodalDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.clinical_embeddings = ClinicalEmbeddings(\"UFNLP/gatortron-base\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        clinical_text = self.data[idx]\n",
    "        embeddings = self.clinical_embeddings.generate_embeddings(clinical_text)\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "# Step 1: Define the Transformer Encoder Model\n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, num_heads, hidden_dim, num_layers):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=input_dim, nhead=num_heads, dim_feedforward=hidden_dim\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            self.encoder_layer, num_layers=num_layers\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.transformer_encoder(x)\n",
    "\n",
    "\n",
    "# Example parameters for the transformer\n",
    "input_dim = 1024  # Size of each input embedding\n",
    "num_heads = 8\n",
    "hidden_dim = 2048\n",
    "num_layers = 6\n",
    "\n",
    "model = TransformerEncoder(input_dim, num_heads, hidden_dim, num_layers)\n",
    "model.to(device)\n",
    "\n",
    "# Example data (replace with actual clinical summaries)\n",
    "\n",
    "for i in range(10):\n",
    "    dummy_data = [\"This is a dummy clinical summary\"] * 32\n",
    "\n",
    "dataset = MultimodalDataset(dummy_data)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "target = torch.rand(32, 1024)  # Replace with actual target variable\n",
    "target = target.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.MSELoss()  # Adjust the criterion based on your specific task\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for embeddings in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(embeddings)\n",
    "        # Assuming you have a target variable corresponding to each embedding\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1} Loss: {loss.item()}\")\n",
    "\n",
    "# Save or use your model as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 0.860691487789154\n",
      "Epoch 2 Loss: 0.65171879529953\n",
      "Epoch 3 Loss: 0.7139180898666382\n",
      "Epoch 4 Loss: 0.6716339588165283\n",
      "Epoch 5 Loss: 0.6878353953361511\n",
      "Epoch 6 Loss: 0.7487881183624268\n",
      "Epoch 7 Loss: 0.7014307975769043\n",
      "Epoch 8 Loss: 0.7196025848388672\n",
      "Epoch 9 Loss: 1.1362229585647583\n",
      "Epoch 10 Loss: 0.7736325263977051\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AdamW\n",
    "\n",
    "model_name = \"bert-base-uncased\"  # Example model, replace with your choice\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "class EmbeddingAdjuster(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(EmbeddingAdjuster, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "\n",
    "# Example: Adjust from 1024 to 768 (BERT's hidden size for the base model)\n",
    "adjuster = EmbeddingAdjuster(1024, 768)\n",
    "adjuster.to(device)\n",
    "\n",
    "\n",
    "class EmbeddingDataset(Dataset):\n",
    "    def __init__(self, embeddings, labels):\n",
    "        self.embeddings = embeddings  # embeddings should be a list of tensors\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.embeddings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        embedding = self.embeddings[idx]\n",
    "        # Add sequence length dimension (assuming embedding is a single token)\n",
    "        embedding = embedding.unsqueeze(0)\n",
    "        return embedding, self.labels[idx]\n",
    "\n",
    "\n",
    "# Example usage\n",
    "# embeddings = [mapped_embedding1, mapped_embedding2, ...]\n",
    "# labels = [label1, label2, ...]\n",
    "# Assuming embeddings is a list of 1D tensors each of shape [1024]\n",
    "embeddings = [torch.rand(1024) for _ in range(8)]  # Example embeddings\n",
    "labels = torch.tensor([0, 1, 0, 1, 0, 1, 0, 1])  # Corresponding labels\n",
    "dataset = EmbeddingDataset(embeddings, labels)\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "optimizer = AdamW(list(model.parameters()) + list(adjuster.parameters()), lr=5e-5)\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch in dataloader:\n",
    "        embeddings, labels = batch\n",
    "        embeddings, labels = embeddings.to(device), labels.to(device)\n",
    "        # Adjust embeddings to match BERT's input size\n",
    "        adjusted_embeddings = adjuster(embeddings)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs_embeds=adjusted_embeddings, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1} Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Dropped Index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 585/585 [00:01<00:00, 315.29it/s]\n",
      "100%|██████████| 585/585 [00:23<00:00, 24.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of embeddings: 585\n",
      "Embedding shape: (512, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aakas\\miniconda3\\envs\\ADA\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.2970\n",
      "Epoch [2/10], Loss: 0.1899\n",
      "Epoch [3/10], Loss: 0.1197\n",
      "Epoch [4/10], Loss: 0.0774\n",
      "Epoch [5/10], Loss: 0.0464\n",
      "Epoch [6/10], Loss: 0.0271\n",
      "Epoch [7/10], Loss: 0.0201\n",
      "Epoch [8/10], Loss: 0.0152\n",
      "Epoch [9/10], Loss: 0.0125\n",
      "Epoch [10/10], Loss: 0.0089\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "from lib.MINDS import MINDS\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from transformers import AutoModel, AutoTokenizer, AutoConfig\n",
    "import redis\n",
    "from redis.commands.search.field import TagField, VectorField\n",
    "from redis.commands.search.indexDefinition import IndexDefinition, IndexType\n",
    "from redis.commands.search.query import Query\n",
    "\n",
    "#  Setting up the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "def generate_summary_from_json(patient_data):\n",
    "    # Initialize an empty list to store sentences\n",
    "    summary_sentences = []\n",
    "\n",
    "    # Iterate through each key-value pair in the JSON object\n",
    "    for key, value in patient_data.items():\n",
    "        # if the key is \"case_id\" then skip it\n",
    "        if key == \"case_id\" or key == \"pathology_report_uuid\":\n",
    "            continue\n",
    "\n",
    "        # remove all _ from the key\n",
    "        key = key.replace(\"_\", \" \")\n",
    "        sentence = f\"{key}: {value};\"\n",
    "\n",
    "        # if the value is a list, then skip it\n",
    "        if isinstance(value, list):\n",
    "            continue\n",
    "\n",
    "        summary_sentences.append(sentence)\n",
    "\n",
    "    # Compile all sentences into a single summary string\n",
    "    summary = \" \".join(summary_sentences)\n",
    "\n",
    "    return summary\n",
    "\n",
    "def process_group(group):\n",
    "    common_fields = {}\n",
    "    nested_objects = []\n",
    "    for col in group.columns:\n",
    "        unique_values = group[col].dropna().unique()\n",
    "        if len(unique_values) == 1:\n",
    "            # If only one unique value exists, it's a common field\n",
    "            common_fields[col] = unique_values[0]\n",
    "\n",
    "    # Create nested objects for fields that are not common\n",
    "    for idx, row in group.iterrows():\n",
    "        nested_object = {\n",
    "            col: row[col]\n",
    "            for col in group.columns\n",
    "            if col not in common_fields and pd.notna(row[col])\n",
    "        }\n",
    "        if nested_object:  # Only add if the nested object is not empty\n",
    "            nested_objects.append(nested_object)\n",
    "\n",
    "    return common_fields, nested_objects\n",
    "\n",
    "def convert_numpy(obj):\n",
    "    if isinstance(obj, np.integer):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, np.floating):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "class ClinincalEmbeddings:\n",
    "    def __init__(self, model):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "        self.config = AutoConfig.from_pretrained(model)\n",
    "        self.model = AutoModel.from_pretrained(model)\n",
    "        self.model = self.model.to(device)\n",
    "\n",
    "    def generate_embeddings(self, sentences):\n",
    "        inputs = self.tokenizer(\n",
    "            str(sentences),\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "\n",
    "        embedding = outputs[\"last_hidden_state\"].cpu().numpy()\n",
    "        return embedding\n",
    "\n",
    "class RedisClient:\n",
    "    def __init__(self):\n",
    "        self.client = redis.Redis(host=\"10.0.1.15\", port=6379, db=0)\n",
    "        self.client.ping()\n",
    "        self.INDEX_NAME = \"clinical\"\n",
    "        self.DOC_PREFIX = \"patient:\"\n",
    "        # drop the index if it already exists\n",
    "        try:\n",
    "            self.client.execute_command(\"FT.DROPINDEX\", self.INDEX_NAME)\n",
    "            print(\"Dropped Index\")\n",
    "        except:\n",
    "            pass\n",
    "        self.create_index()\n",
    "\n",
    "    def create_index(self):\n",
    "        schema = (\n",
    "            TagField(\"case_submitter_id\"),\n",
    "            VectorField(\n",
    "                \"embedding\",\n",
    "                \"FLAT\",\n",
    "                {\n",
    "                    \"TYPE\": \"FLOAT64\",\n",
    "                    \"DIM\": 512 * 1024,\n",
    "                    \"DISTANCE_METRIC\": \"COSINE\",\n",
    "                },\n",
    "            ),\n",
    "        )\n",
    "        definition = IndexDefinition(\n",
    "            prefix=[self.DOC_PREFIX], index_type=IndexType.HASH\n",
    "        )\n",
    "        self.client.ft(self.INDEX_NAME).create_index(\n",
    "            fields=schema, definition=definition\n",
    "        )\n",
    "\n",
    "    def add_document(self, case_id, embedding):\n",
    "        embedding = embedding.astype(np.float64).tobytes()\n",
    "        pipe = self.client.pipeline()\n",
    "        pipe.hset(\n",
    "            self.DOC_PREFIX + case_id,\n",
    "            mapping={\"case_submitter_id\": case_id},\n",
    "        )\n",
    "        pipe.hset(\n",
    "            self.DOC_PREFIX + case_id,\n",
    "            mapping={\"embedding\": embedding},\n",
    "        )\n",
    "        pipe.execute()\n",
    "\n",
    "    def query(self, query):\n",
    "        result = np.frombuffer(self.client.hget(query, \"embedding\"), dtype=np.float64)\n",
    "        return result\n",
    "\n",
    "class EmbeddingsDataset(Dataset):\n",
    "    def __init__(self, embeddings):\n",
    "        \"\"\"\n",
    "        Constructor for the Dataset.\n",
    "        Args:\n",
    "        embeddings (list of numpy arrays): The embeddings generated from clinical reports.\n",
    "        \"\"\"\n",
    "        self.embeddings = [torch.tensor(e, dtype=torch.float32) for e in embeddings]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the total number of samples in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.embeddings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieves the item (embedding) at the specified index.\n",
    "        Args:\n",
    "        idx (int): The index of the item to retrieve.\n",
    "        Returns:\n",
    "        Tensor: The embedding at the specified index.\n",
    "        \"\"\"\n",
    "        return self.embeddings[idx].to(device)\n",
    "    \n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, n_layers, n_heads, dropout_rate):\n",
    "        \"\"\"\n",
    "        Constructor for the TransformerModel.\n",
    "        Args:\n",
    "        input_dim (int): Dimension of the input embeddings.\n",
    "        hidden_dim (int): The dimension of the hidden layer.\n",
    "        n_layers (int): Number of transformer layers.\n",
    "        n_heads (int): Number of heads in the MultiHeadAttention layer.\n",
    "        dropout_rate (float): Dropout rate.\n",
    "        \"\"\"\n",
    "        super(TransformerModel, self).__init__()\n",
    "        # Transformer layers\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=input_dim, \n",
    "            nhead=n_heads, \n",
    "            dim_feedforward=hidden_dim, \n",
    "            dropout=dropout_rate\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the model.\n",
    "        Args:\n",
    "        x (Tensor): Input tensor (embeddings).\n",
    "        Returns:\n",
    "        Tensor: The output of the transformer encoder.\n",
    "        \"\"\"\n",
    "        transformed = self.transformer_encoder(x)\n",
    "        return transformed\n",
    "\n",
    "def train_model(model, criterion, optimizer, dataloader, num_epochs=10):\n",
    "    \"\"\"\n",
    "    Trains the model.\n",
    "    Args:\n",
    "    model (nn.Module): The model to train.\n",
    "    criterion (nn.Module): The loss function.\n",
    "    optimizer (torch.optim): The optimizer to use.\n",
    "    dataloader (DataLoader): The DataLoader object.\n",
    "    num_epochs (int): Number of epochs to train the model for.\n",
    "    \"\"\"\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, embeddings in enumerate(dataloader):\n",
    "            # Forward pass\n",
    "            outputs = model(embeddings)\n",
    "            # Compute the loss\n",
    "            loss = criterion(outputs, embeddings)\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "\n",
    "def main():\n",
    "    minds = MINDS()\n",
    "    clinical_model = ClinincalEmbeddings(model=\"UFNLP/gatortron-base\")\n",
    "    redis_client = RedisClient()\n",
    "\n",
    "    project_id = \"TCGA-LUAD\"\n",
    "    filename = project_id\n",
    "    tables = minds.get_tables()\n",
    "\n",
    "    if Path(f\"{filename}.json\").exists():\n",
    "        json_objects = json.load(open(f\"{filename}.json\"))\n",
    "    else:\n",
    "        json_objects = {}\n",
    "        for table in tqdm(tables[\"Tables_in_nihnci\"]):\n",
    "            query = f\"SELECT * FROM nihnci.{table} WHERE project_id='{project_id}'\"\n",
    "            df = minds.query(query)\n",
    "            for case_id, group in tqdm(df.groupby(\"case_submitter_id\"), leave=False):\n",
    "                if case_id not in json_objects:\n",
    "                    json_objects[case_id] = {}\n",
    "                common_fields, nested_objects = process_group(group)\n",
    "                json_objects[case_id].update(common_fields)\n",
    "                json_objects[case_id][table] = nested_objects\n",
    "        with open(f\"{filename}.json\", \"w\") as fp:\n",
    "            json.dump(json_objects, fp, indent=4, default=convert_numpy)\n",
    "\n",
    "    # if the redis already has the embeddings, for a given patient, then skip\n",
    "    for case_id, patient_data in tqdm(json_objects.items()):\n",
    "        if redis_client.client.exists(f\"patient:{case_id}\"):\n",
    "            continue\n",
    "        summary = generate_summary_from_json(patient_data)\n",
    "        embedding = clinical_model.generate_embeddings(summary)\n",
    "        redis_client.add_document(case_id, embedding)\n",
    "\n",
    "    embeddings = []\n",
    "    for case_id, patient_data in tqdm(json_objects.items()):\n",
    "        embedding = redis_client.query(f\"patient:{case_id}\")\n",
    "        embedding = embedding.reshape(512, 1024)\n",
    "        embeddings.append(embedding)\n",
    "\n",
    "    print(f'Number of embeddings: {len(embeddings)}')\n",
    "    print(f'Embedding shape: {embeddings[0].shape}')\n",
    "\n",
    "    # Create the dataset and DataLoader\n",
    "    dataset = EmbeddingsDataset(embeddings)\n",
    "    dataloader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "    # Model parameters\n",
    "    input_dim = 1024  # Embedding dimension\n",
    "    hidden_dim = 2048  # Hidden dimension\n",
    "    n_layers = 4  # Number of transformer layers\n",
    "    n_heads = 8  # Number of heads in MultiHeadAttention\n",
    "    dropout_rate = 0.1  # Dropout rate\n",
    "\n",
    "    # Initialize the model and move it to the device\n",
    "    model = TransformerModel(input_dim, hidden_dim, n_layers, n_heads, dropout_rate).to(device)\n",
    "    # Loss function\n",
    "    criterion = nn.MSELoss()\n",
    "    # Optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    # Train the model\n",
    "    train_model(model, criterion, optimizer, dataloader, num_epochs=10)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ADA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
